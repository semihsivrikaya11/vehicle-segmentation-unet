{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "E8d0euBkCNYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('/content/drive/MyDrive/gtFine_trainvaltest.zip', '/content/')\n",
        "shutil.copy('/content/drive/MyDrive/leftImg8bit_trainvaltest.zip', '/content/')\n",
        "\n",
        "print(\"Zip files have been copied to the '/content/' directory.\")\n"
      ],
      "metadata": {
        "id": "0VkgB7MwCfa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the zip files\n",
        "with zipfile.ZipFile('/content/gtFine_trainvaltest.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/gtFine_trainvaltest/')\n",
        "\n",
        "with zipfile.ZipFile('/content/leftImg8bit_trainvaltest.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/leftImg8bit_trainvaltest/')\n",
        "\n",
        "print(\"Zip files have been successfully extracted inside the '/content/' directory.\")\n"
      ],
      "metadata": {
        "id": "Lmvd3uTHjXNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torch.amp import autocast, GradScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ResNet34 + UNet Model\n",
        "class ResNetUNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(ResNetUNet, self).__init__()\n",
        "        base_model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "        base_layers = list(base_model.children())\n",
        "        self.layer0 = nn.Sequential(*base_layers[:3])\n",
        "        self.layer1 = nn.Sequential(*base_layers[3:5])\n",
        "        self.layer2 = base_model.layer2\n",
        "        self.layer3 = base_model.layer3\n",
        "        self.layer4 = base_model.layer4\n",
        "        self.upconv4 = self._upsample(512, 256)\n",
        "        self.upconv3 = self._upsample(256, 128)\n",
        "        self.upconv2 = self._upsample(128, 64)\n",
        "        self.upconv1 = self._upsample(64, 64)\n",
        "        self.conv_last = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def _upsample(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.layer0(x)\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "        x = self.upconv4(x4)\n",
        "        x = self.upconv3(x)\n",
        "        x = self.upconv2(x)\n",
        "        x = self.upconv1(x)\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        return self.conv_last(x)\n",
        "\n",
        "# Dataset (Only vehicle classes)\n",
        "class CityscapesVehicleDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_dir, transform=None):\n",
        "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, '**', '*.png'), recursive=True))\n",
        "        self.label_paths = sorted(glob.glob(os.path.join(label_dir, '**', '*_labelIds.png'), recursive=True))\n",
        "        self.image_transform = transform\n",
        "        self.label_resize = transforms.Resize((224, 224), interpolation=Image.NEAREST)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        label = Image.open(self.label_paths[idx]).convert(\"L\")\n",
        "        label = self.label_resize(label)\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "        label = np.array(label)\n",
        "        label = ((label == 26) | (label == 27) | (label == 28) | (label == 31)).astype(np.float32)\n",
        "        label = torch.from_numpy(label).unsqueeze(0)\n",
        "        return image, label\n",
        "\n",
        "# Transforms & Paths\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "IMAGE_ROOT = '/content/leftImg8bit_trainvaltest/leftImg8bit/train'\n",
        "LABEL_ROOT = '/content/gtFine_trainvaltest/gtFine/train'\n",
        "\n",
        "dataset = CityscapesVehicleDataset(IMAGE_ROOT, LABEL_ROOT, transform)\n",
        "loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNetUNet(n_classes=1).to(device)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([20.0]).to(device))\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training Loop\n",
        "EPOCHS = 50\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(device_type=\"cuda\"):\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Debug + Metrics\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_image, test_label = dataset[0]\n",
        "        test_image = test_image.unsqueeze(0).to(device)\n",
        "        test_label = test_label.unsqueeze(0).to(device)\n",
        "        pred_logits = model(test_image)\n",
        "        pred = torch.sigmoid(pred_logits)\n",
        "        pred_np = pred[0, 0].cpu().numpy()\n",
        "        label_np = test_label[0, 0].cpu().numpy()\n",
        "        pred_bin = (pred > 0.2).float()\n",
        "\n",
        "        if test_label.sum() == 0:\n",
        "            print(\"Warning: No vehicle pixels in this batch.\")\n",
        "        else:\n",
        "            print(f\"[Epoch {epoch+1}] Mask Mean: {label_np.mean():.4f} | Pred Mean: {pred_np.mean():.4f} | Max: {pred_np.max():.4f} | Min: {pred_np.min():.4f} | Std: {pred_np.std():.4f}\")\n",
        "            intersection = (pred_bin * test_label).sum()\n",
        "            union = pred_bin.sum() + test_label.sum()\n",
        "            iou = (intersection / (union - intersection + 1e-6)).item()\n",
        "            dice = (2 * intersection / (union + 1e-6)).item()\n",
        "            print(f\"IOU: {iou:.4f} | Dice: {dice:.4f}\")\n",
        "\n",
        "        plt.imsave(f\"/content/debug_mask_ep{epoch+1}.png\", label_np * 255, cmap=\"gray\")\n",
        "        plt.imsave(f\"/content/debug_pred_ep{epoch+1}.png\", (pred_np > 0.2).astype(np.uint8) * 255, cmap=\"gray\")\n",
        "        plt.hist(pred_np.flatten(), bins=50)\n",
        "        plt.title(f\"Prediction Histogram (Epoch {epoch+1})\")\n",
        "        plt.savefig(f\"/content/debug_pred_hist_ep{epoch+1}.png\")\n",
        "        plt.close()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        weight_path = f\"/content/final_resnet_unet_epoch_{epoch+1}.pth\"\n",
        "        torch.save(model.state_dict(), weight_path)\n",
        "        shutil.copy(weight_path, f\"/content/drive/MyDrive/final_resnet_unet_epoch_{epoch+1}.pth\")\n",
        "        print(f\"Saved to Drive: final_resnet_unet_epoch_{epoch+1}.pth\")\n",
        "\n",
        "# Save final model\n",
        "torch.save(model.state_dict(), \"/content/final_resnet_unet_model.pth\")\n",
        "shutil.copy(\"/content/final_resnet_unet_model.pth\", \"/content/drive/MyDrive/final_resnet_unet_model.pth\")\n",
        "print(\"Final model saved.\")\n"
      ],
      "metadata": {
        "id": "pEid307fQrou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GuiLcOjuZ1Pd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
